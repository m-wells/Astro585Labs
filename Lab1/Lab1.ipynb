{
 "metadata": {
  "language": "Julia",
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Lab 1: Mark Wells"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Problem 1"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am using iJulia w/ the PyPlot graphics handler on my personal computer sporting an Intel Core i7 processor running Fedora 19 (64 bit)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Problem 2"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2a"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "srand(42);\n",
      "N=10000;\n",
      "true_mean=10000.;\n",
      "y=true_mean+randn(N);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_mean=mean(y);\n",
      "sample_var=var(y);\n",
      "(sample_mean,sample_var)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "(9999.998011659798,1.0199227833780644)"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2b"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y32bit = convert(Array{Float32,1},y);\n",
      "y16bit = convert(Array{Float16,1},y);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_mean_32bit=mean(y32bit);\n",
      "sample_var_32bit=var(y32bit);\n",
      "(sample_mean_32bit,sample_var_32bit)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "(9999.998f0,1.0199206f0)"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_mean_16bit=mean(y16bit);\n",
      "sample_var_16bit=var(y16bit);\n",
      "(sample_mean_16bit,sample_var_16bit)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "(Inf32,Inf32)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Fractional differences"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abs(sample_mean-sample_mean_32bit)/sample_mean"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "3.52152089351513e-9"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abs(sample_var-sample_var_32bit)/sample_var"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "2.152945720349752e-6"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The 32-bit float operations/data are able to preserve 7 significant figures as compared to the 64-bit which can store up to 16 significant figures.  The 16-bit float does not have the capacity to perform these operations without overflowing.  The 32-bit mean matches the 64-bit mean (save for the truncation after 7 significant figures) while the variance begins to show errors at the order of millionths.  The variance induces more error because the calculation for variance depends upon the calculation of the mean.  The 64-bit mean value has more significant figures than the 32-bit (and 16-bit) value(s) and therefore will minimize the error in the calculations."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2c"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we increased N to 10^5, the discrepancy between the 64-bit and the 32-bit variance calculation should get larger but would still overflow the 16-bit.  We may begin to see the mean suffer in the 32-bit data since due to accumulation error.\n",
      "If we increased the true mean then more significant figures would need to be stored and we would lose precision."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2d"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Increasing N"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "srand(42);\n",
      "N=10^5;\n",
      "true_mean=10000.;\n",
      "y=true_mean+randn(N);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y32bit=convert(Array{Float32,1},y);\n",
      "y16bit=convert(Array{Float16,1},y);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_mean=mean(y);\n",
      "sample_var=var(y);\n",
      "(sample_mean,sample_var)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "(10000.0031598515,1.0088883985077686)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_mean_32bit=mean(y32bit);\n",
      "sample_var_32bit=var(y32bit);\n",
      "(sample_mean_32bit,sample_var_32bit)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "(10000.003f0,1.0088867f0)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_mean_16bit=mean(y16bit);\n",
      "sample_var_16bit=var(y16bit);\n",
      "(sample_mean_16bit,sample_var_16bit)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "(Inf32,Inf32)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Fractional differences"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abs(sample_mean-sample_mean_32bit)/sample_mean"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "2.301639270029202e-8"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abs(sample_var-sample_var_32bit)/sample_var"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "1.6885907588975298e-6"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It appears my guesses were not very accurate.  Increasing the number of operations does not seem to have a significant impact on the mean and variance of the system."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Increasing true_mean"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "srand(42);\n",
      "N=10^4;\n",
      "true_mean=10.^5;\n",
      "y=true_mean+randn(N);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y32bit=convert(Array{Float32,1},y);\n",
      "y16bit=convert(Array{Float16,1},y);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_mean=mean(y);\n",
      "sample_var=var(y);\n",
      "(sample_mean,sample_var)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "(99999.9980116598,1.0199227833780122)"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_mean_32bit=mean(y32bit);\n",
      "sample_var_32bit=var(y32bit);\n",
      "(sample_mean_32bit,sample_var_32bit)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "(100000.0f0,1.0200287f0)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample_mean_16bit=mean(y16bit);\n",
      "sample_var_16bit=var(y16bit);\n",
      "(sample_mean_16bit,sample_var_16bit)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "(Inf32,NaN32)"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Fractional differences"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abs(sample_mean-sample_mean_32bit)/sample_mean"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "1.9883402378301593e-8"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "abs(sample_var-sample_var_32bit)/sample_var"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "0.00010385784983873483"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Increasing the true_mean did indeed have an impact on the system. The 32-bit mean is no longer distinguishable from the true mean so all precision in the mean has been lost. The error in the variance has gone up by a factor of 1000."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2e"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This exercise shows why it is important to understand what level of precision is needed.  I would say that it has taught me when in doubt, opt for higher precision (64-bit).  The only time one should consider using lower precision is when memory limitations become a factor."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Problem 3"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function mean_demo(y::Array)  # the syntax ::Array specifies that this function can only be applied if argument is an array.\n",
      "   n = length(y);         # get the number of elements in the array y\n",
      "   sum = zero(y[1]);  # using zero(y[1]) makes sum have the same data type as y[1]\n",
      "   for i in 1:n              # In Julia and Fortran, arrays start a 1, not 0 (like in C arrays and Python lists)\n",
      "      sum = sum + y[i];\n",
      "   end;                 # semi-colons are unnecessary, but can be useful when pasting code\n",
      "interactively\n",
      "   return sum/n;  # return isn\u2019t necessary since functions return the last value by default\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "mean_demo (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3a"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function onepassvar(y::Array)\n",
      "    n=length(y);\n",
      "    sum=zero(y[1]);\n",
      "    m=mean_demo(y);\n",
      "    for i in 1:n\n",
      "        sum=sum+(y[i]-m)^2;\n",
      "    end;\n",
      "    return sum/(n-1);\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "onepassvar (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3b"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function twopassvar(y::Array)\n",
      "    n=length(y);\n",
      "    ptsum=zero(y);\n",
      "    sum=zero(y[1]);\n",
      "    m=mean_demo(y);\n",
      "    for i in 1:n\n",
      "        ptsum[i]=(y[i]-m)^2;\n",
      "    end;\n",
      "    for i in 1:n\n",
      "        sum=sum+ptsum[i];\n",
      "    end;\n",
      "    return sum/(n-1);\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "twopassvar (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3c"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "srand(42);\n",
      "N=10^6;\n",
      "true_mean=10.^6;\n",
      "y=true_mean+randn(N);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(onepassvar(y)-var(y))/var(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "-8.867875425917323e-16"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(twopassvar(y)-var(y))/var(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "-8.867875425917323e-16"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Both of these functions appear to operating near machine precision.  I don't see much difference between accuracy wise."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3d"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I suppose memory management and total time operations would be the main considerations between these two above functions.  The onepass is almost surely more efficient memory and time wise while the twopass would be slower and consume more memory.  The only redeption with the twopass is it might be more robust to overflow but that is only a guess on my part."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3e"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function var_online(y::Array)\n",
      "  n = length(y);\n",
      "  sum1 = zero(y[1]);\n",
      "  mean = zero(y[1]);\n",
      "  M2 = zero(y[1]);\n",
      "  for i in 1:n\n",
      "        diff_by_i = (y[i]-mean)/i;\n",
      "        mean = mean +diff_by_i;\n",
      "        M2 = M2 + (i-1)*diff_by_i*diff_by_i+(y[i]-mean)*(y[i]-mean);\n",
      "  end;\n",
      "  variance = M2/(n-1);\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "var_online (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(var_online(y)-var(y))/var(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "4.149899663066529e-11"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This function appears to be optimal for speed but it suffers precision issues.  This would be a good choice if you need to do many operations of this sort and this level of precision should suffice.  However, if high precision is critical this may not be a good choice.\n",
      "\n",
      "Another interesting thing about the online function is that the larger the input array becomes the less the mean should suffer.  If you wanted continous operation then you could slightly modify this to return the variance at each step and let it run.  The mean should become well behaved if you keep feeding values in."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Problem 4"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "4a"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "srand(42);\n",
      "N_obs=100;\n",
      "true_vel=zeros(N_obs);\n",
      "sigma=2.*ones(N_obs);\n",
      "meas_uncert=sigma .* randn(N_obs);\n",
      "sim_obs=true_vel+meas_uncert;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "4b"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prob_ygivenz(y::Float64,z::Float64,sigma::Float64)=exp((-(y-z)^2)/(2*sigma^2))/(sqrt(2*pi*sigma^2));"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "4c"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function set_likelihood(y::Array,sigma::Array,z::Array)\n",
      "    n=length(y);\n",
      "    set_product=one(y[1]);\n",
      "    for i in 1:n\n",
      "        set_product=set_product*prob_ygivenz(y[i],z[i],sigma[i])\n",
      "    end;\n",
      "    return set_product\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "set_likelihood (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "4d"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "srand(42);\n",
      "N_obs=100;\n",
      "true_vel=zeros(N_obs);\n",
      "sigma=2.*ones(N_obs);\n",
      "meas_uncert=sigma .* randn(N_obs);\n",
      "sim_obs=true_vel+meas_uncert;\n",
      "set_likelihood(sim_obs,meas_uncert,true_vel)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "3.776467160177523e-61"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "srand(42);\n",
      "N_obs=600;\n",
      "true_vel=zeros(N_obs);\n",
      "sigma=2.*ones(N_obs);\n",
      "meas_uncert=sigma .* randn(N_obs);\n",
      "sim_obs=true_vel+meas_uncert;\n",
      "set_likelihood(sim_obs,meas_uncert,true_vel)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "0.0"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "4d"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I think this is possible.  The probability of getting a specific 100 observations would be pretty low so this seems plausible.  The case of N_obs=600 is even smaller and appears to be below machine precision."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "4e"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function log_set_likelihood(y::Array,sigma::Array,z::Array)\n",
      "    n = length(y);\n",
      "    sum = zero(y[1]);\n",
      "    for i in 1:n\n",
      "        sum = sum + log(prob_ygivenz(y[i],z[i],sigma[i]));\n",
      "    end;\n",
      "    return sum;\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "log_set_likelihood (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "srand(42);\n",
      "N_obs=100;\n",
      "true_vel=zeros(N_obs);\n",
      "sigma=2.*ones(N_obs);\n",
      "meas_uncert=sigma .* randn(N_obs);\n",
      "sim_obs=true_vel+meas_uncert;\n",
      "log_set_likelihood(sim_obs,meas_uncert,true_vel)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "-139.1289017137387"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "srand(42);\n",
      "N_obs=600;\n",
      "true_vel=zeros(N_obs);\n",
      "sigma=2.*ones(N_obs);\n",
      "meas_uncert=sigma .* randn(N_obs);\n",
      "sim_obs=true_vel+meas_uncert;\n",
      "log_set_likelihood(sim_obs,meas_uncert,true_vel)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "-895.3145308517977"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The probability of obtaining the results are incredibly small.  The differences between these results and the ones obtained in part 4c are that the results are all non-zero and the magnitude is much smaller for the set of 100 observations while the results for the 600 observations are now non-zero."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "4f"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The exercise has illustrated that precision is important.  When dealing with very small values the computer can experience difficulties.  There are ways to preserve precision by being careful and planning.  Testing your results using a variety of methods can give confidence that the methods are working properly and behave at different limits and values.\n",
      "\n",
      "When writing code for research, it is important to remember these lessons and to take care to eliminate precision issues."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function round_down_to_power_of_ten(x::Real)\n",
      "    z = 1.0;\n",
      "    if x >= 1.0;\n",
      "        while z*10.<=x\n",
      "            z = z * 10.0;\n",
      "            end;\n",
      "    else\n",
      "        while z >= x\n",
      "            z = z / 10.0;\n",
      "            end;\n",
      "        end;\n",
      "    return z;\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "round_down_to_power_of_ten (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The function does not handle 0.\n",
      "The function could easily be implemented using logs.\n",
      "The function does not handle negative values."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}